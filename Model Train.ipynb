{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f47bdf",
   "metadata": {},
   "source": [
    "# Libirary import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d712b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" os \"\"\"\n",
    "import os\n",
    "\n",
    "\"\"\" torch \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import Tensor\n",
    "\n",
    "\"\"\"tensor board\"\"\"\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\"\"\"glob\"\"\"\n",
    "from glob import glob\n",
    "\n",
    "\"\"\" tqdm \"\"\"\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"Pandas\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" numpy \"\"\"\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"JSON\"\"\"\n",
    "import json\n",
    "\n",
    "\"\"\"sklearn\"\"\"\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\"\"\"seaborn\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"scipy\"\"\"\n",
    "from scipy import io\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft,fftfreq\n",
    "\n",
    "\"\"\"SUMMARY\"\"\"\n",
    "from torchsummary import summary as summary_\n",
    "\n",
    "\"\"\"time\"\"\"\n",
    "import time\n",
    "\n",
    "\"\"\"PIL\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"einops\"\"\"\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0466e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(labels, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(labels,preds).ravel()\n",
    "    \n",
    "    sen =  (tp/(tp+fn))*100\n",
    "    spe =  (tn/(fp+tn))*100\n",
    "    \n",
    "    ppv =  (tp/(tp+fp))*100\n",
    "    npv =  (tn/(fn+tn))*100\n",
    "    \n",
    "    return tn, fp, fn, tp, sen,spe,ppv,npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75202cec",
   "metadata": {},
   "source": [
    "# Path init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2114678",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9219",
   "metadata": {},
   "source": [
    "## Male Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa192a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = \n",
    "result_save_path = ''\n",
    "\n",
    "gender = 'male'\n",
    "pos_class = 494\n",
    "neg_class = 7143"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ea8d5",
   "metadata": {},
   "source": [
    "## Female Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96625a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = \n",
    "result_save_path = ''\n",
    "\n",
    "gender = 'female'\n",
    "pos_class = 1455\n",
    "neg_class = 4655"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83226e39",
   "metadata": {},
   "source": [
    "## Total Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = \n",
    "result_save_path = ''\n",
    "\n",
    "pos_class = 494+1455\n",
    "neg_class = 7143+4655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = result_save_path + str(experiment_num)\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(folder_path)):\n",
    "        os.makedirs(os.path.join(folder_path))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538bc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = result_save_path + str(experiment_num)+'/prob and auroc figure per epoch'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(folder_path2)):\n",
    "        os.makedirs(os.path.join(folder_path2))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Result init\"\"\"\n",
    "Result = {}\n",
    "Result['Data status']   = 'Normal, Mildly vs  Moderately, Severely + Male cut off: 132, Female cut off: 109'\n",
    "Result['Data Balanced'] = 'Unbalanced'\n",
    "Result['class weight']  = 'True'\n",
    "Result['preprocess']  = '132,109'\n",
    "Result['Model']  = 'coatmixer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ae71f",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "#validation ratio\n",
    "validation_ratio = 0.1\n",
    "\n",
    "#learning rate\n",
    "lr = 0.001\n",
    "\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "no_cuda = False\n",
    "\n",
    "log_interval = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293baf2",
   "metadata": {},
   "source": [
    "# Set the seed and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers':0,'pin_memory':True} if use_cuda else {}\n",
    "\n",
    "!nvcc --version\n",
    "#https://pytorch.org/get-started/previous-versions/\n",
    "print('--------------------------------------')\n",
    "print('현재 torch 버전:',torch.__version__)\n",
    "print('학습을 진행하는 기기:',device)\n",
    "print('cuda index:', torch.cuda.current_device())\n",
    "print('gpu 개수:', torch.cuda.device_count())\n",
    "print('graphic name:', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f8a70",
   "metadata": {},
   "source": [
    "# CoAtMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa900c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coatmixer import coatmixer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,12,4000)\n",
    "\n",
    "\n",
    "model = coatmixer_0()\n",
    "\n",
    "output = model.forward(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0a575",
   "metadata": {},
   "source": [
    "# ResNet-CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_cbam_1d import ResNetCBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,12)\n",
    "\n",
    "layer = ResNetCBAM()\n",
    "\n",
    "output = layer(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a383e",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, oup1:int=768, oup2:int=32, class_n:int=1):\n",
    "        super(Ensemble_CNN,self).__init__()\n",
    "        \n",
    "        \"\"\"ECG processing model\"\"\"\n",
    "        self.FE_Global    = coatmixer_0()\n",
    "        \n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        \"\"\"Features processing model\"\"\"\n",
    "        self.seq2 = ResNetCBAM()\n",
    "        \n",
    "        \n",
    "        \"\"\"FC\"\"\"\n",
    "        self.seq3 = nn.Sequential(\n",
    "            nn.Linear(oup1+oup2, int((oup1+oup2)/8)),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int((oup1+oup2)/8), int((oup1+oup2)/32) ),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int((oup1+oup2)/32), class_n)\n",
    "            )\n",
    "        \n",
    "        \"\"\"CAM\"\"\"\n",
    "        self.gradients_global = None\n",
    "\n",
    "        \n",
    "    def activations_hook_global(self, grad):\n",
    "        self.gradients_global = grad\n",
    "\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        \n",
    "        \"\"\"intput\"\"\"\n",
    "        global_features = self.FE_Global(x)\n",
    "        # hook for grad cam\n",
    "        if global_features.requires_grad:\n",
    "            h = global_features.register_hook(self.activations_hook_global)\n",
    "        global_features = self.seq1(global_features)\n",
    "        \n",
    "        \"\"\"intput\"\"\"\n",
    "        ECG_features = self.seq2(y)\n",
    "        \n",
    "        \"\"\"concat\"\"\"\n",
    "        out = torch.cat((global_features, ECG_features), dim= -1)\n",
    "        out = self.seq3(out)\n",
    "        return out\n",
    "    \n",
    "    def get_activations_gradient_global(self):\n",
    "        # method for the gradient extraction\n",
    "        return self.gradients_global\n",
    "    \n",
    "    def get_activations_global(self, x):\n",
    "        # method for the activation exctraction\n",
    "        return self.FE_Global(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8364803",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,12,4000)\n",
    "#additional_features = torch.randn(1,12)\n",
    "additional_features = torch.randn(1, 1,12)\n",
    " \n",
    "\n",
    "\n",
    "model = Ensemble_CNN()\n",
    "output = model.forward(input, additional_features)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f387df2",
   "metadata": {},
   "source": [
    "# Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6359718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LVH\"\"\"\n",
    "with open('', 'r') as f:\n",
    "    train = json.load(f)\n",
    "    \n",
    "with open('', 'r') as f:\n",
    "    validation = json.load(f)\n",
    "    \n",
    "with open('', 'r') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train),len(validation),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdf9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_selection(json_list, gender):\n",
    "    \n",
    "    label_data = json_list\n",
    "    if gender == 'male':\n",
    "        sex = '1'\n",
    "    elif gender == 'female':\n",
    "        sex = '2'\n",
    "        \n",
    "    new_label_data = []\n",
    "    \n",
    "    for i in range(0,len(label_data),1):\n",
    "        tempt = label_data[i]\n",
    "        if tempt['sex'] == sex:\n",
    "            new_label_data.append(tempt)\n",
    "            \n",
    "    return new_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = gender_selection(train, gender)\n",
    "validation = gender_selection(validation, gender)\n",
    "test = gender_selection(test, gender)\n",
    "\n",
    "len(train),len(validation),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466aadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths       = train\n",
    "validation_paths  = validation\n",
    "test_paths        = test\n",
    "\n",
    "len(train_paths), len(validation_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5225f",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "          \n",
    "        \"\"\"get data\"\"\"\n",
    "        tempt = self.data_paths[idx] \n",
    "        path = tempt['data_path']\n",
    "        data = np.load(file = path)\n",
    "        \n",
    "        LeadI   = data[0][500:-500]\n",
    "        LeadII  = data[1][500:-500]\n",
    "        LeadIII = data[2][500:-500]\n",
    "        V1      = data[3][500:-500]\n",
    "        V2      = data[4][500:-500]\n",
    "        V3      = data[5][500:-500]\n",
    "        V4      = data[6][500:-500]\n",
    "        V5      = data[7][500:-500]\n",
    "        V6      = data[8][500:-500]\n",
    "        aVL     = data[9][500:-500]\n",
    "        aVR     = data[10][500:-500]\n",
    "        aVF     = data[11][500:-500]\n",
    "\n",
    "        data = np.vstack([LeadI, LeadII, LeadIII,aVR, aVL, aVF, V1, V2, V3, V4, V5, V6])\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        \n",
    "        \n",
    "        sex = float(tempt['sex'])\n",
    "        age = float(tempt['age'])\n",
    "        \n",
    "        \"\"\"ecg features\"\"\"\n",
    "        VentricularRate = float(tempt['VentricularRate'])\n",
    "        AtrialRate      = float(tempt['AtrialRate'])\n",
    "        PRInterval      = float(tempt['PRInterval']) \n",
    "        QRSDuration     = float(tempt['QRSDuration'])\n",
    "        QTInterval      = float(tempt['QTInterval'])\n",
    "        QTCorrected     = float(tempt['QTCorrected'])\n",
    "        PAxis           = float(tempt['PAxis'])\n",
    "        RAxis           = float(tempt['RAxis'])\n",
    "        TAxis           = float(tempt['TAxis'])\n",
    "        AFIB_AFL        = float(tempt['fibrillation or flutter'])\n",
    "        \n",
    "        \n",
    "        features = np.array([sex,age,VentricularRate,AtrialRate,PRInterval,QRSDuration,\n",
    "                             QTInterval,QTCorrected,PAxis,RAxis,TAxis,AFIB_AFL])\n",
    "        \n",
    "        \n",
    "        features = np.expand_dims(features, axis=0)\n",
    "        \n",
    "\n",
    "        \"\"\"get label\"\"\"\n",
    "        if sex == 1.0:\n",
    "            if float(tempt['LV mass index']) < 132:  \n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "        else:\n",
    "            if float(tempt['LV mass index']) < 109: \n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "               \n",
    "        \n",
    "        return data,features,label\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f267b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset      = CustomDataset(train_paths,transforms.Compose([transforms.ToTensor()]))\n",
    "validation_dataset = CustomDataset(validation_paths,transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset       = CustomDataset(test_paths,transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a041ffe",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c620a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, \n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "\"\"\"Validation\"\"\"\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "\"\"\"Test\"\"\"\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size = test_batch_size,\n",
    "    shuffle = False,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "print(\"Length of the train_loader:\", len(train_loader))\n",
    "print(\"Length of the val_loader:\", len(validation_loader))\n",
    "print(\"Length of the test_loader:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca8cf5",
   "metadata": {},
   "source": [
    "# Calculate pos_weight for unbalanced class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b09da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = 0\n",
    "neg_class = 0\n",
    "\n",
    "for batch_idx,(data,_,target) in enumerate(train_loader):\n",
    "    \n",
    "    pos_class += len(target[np.where(target == 1)])\n",
    "    neg_class += len(target[np.where(target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee694f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_weight = num_neg / num_pos\n",
    "pos_weight = torch.tensor([neg_class/pos_class], dtype = torch.float32)\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d02617",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['pos_weight']  = pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ececd36",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c21ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ensemble_CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "Result['optimizer']   = 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee0742",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc53afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "train_losses        = []\n",
    "avg_train_losses    = []\n",
    "Train_baths_ACC     = [] \n",
    "Train_ACC           = [] \n",
    "Train_AUROC         = []\n",
    "\n",
    "\n",
    "\"\"\"Validaion\"\"\"\n",
    "valid_losses        = []\n",
    "avg_valid_losses    = []\n",
    "Validation_ACC      = []\n",
    "Valid_ACC_per_Class = []\n",
    "Validation_AUROC    = []\n",
    "\n",
    "\n",
    "Validation_Sen      = []\n",
    "Validation_Spe      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class num and loss\"\"\"\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight.cuda())\n",
    "\n",
    "\"\"\"save best model\"\"\"\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "best_auroc = 0\n",
    "train_acc_cul = 0\n",
    "\n",
    "best_model_save_path = folder_path +'/'+ 'best model of experiment ' + str(experiment_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16fe0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    \"\"\"Train\"\"\"\n",
    "    \n",
    "    train_prob_auroc_save_path = folder_path2 + '/epoch = ' + str(epoch) + '/train'\n",
    "\n",
    "    try:\n",
    "        if not(os.path.isdir(train_prob_auroc_save_path)):\n",
    "            os.makedirs(os.path.join(train_prob_auroc_save_path))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    Train_baths_ACC = []\n",
    "    \n",
    "    true_labels  = np.array([]) # ideal label\n",
    "    target_score = np.array([]) # ouput score\n",
    "    prob_score   = np.array([]) # ouput prob\n",
    "    \n",
    "    for batch_idx, (data,features,target) in enumerate(train_loader):\n",
    "    \n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        features = features.to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data,features)\n",
    "         \n",
    "        \"\"\"pred(BCE loss)\"\"\"\n",
    "        pred = torch.round(torch.sigmoid(output))\n",
    "        \n",
    "        \"\"\"loss\"\"\"\n",
    "        loss = criterion(output.view_as(target), target)\n",
    "        \n",
    "        \"\"\"update and save loss\"\"\"\n",
    "        train_loss += loss.item()\n",
    "        loss.backward() # 가중치 갱신.\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        correct = 0\n",
    "        total = target.size(0)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / total\n",
    "        Train_baths_ACC.append(accuracy)\n",
    "        \n",
    "        \"\"\"auroc inputs\"\"\"\n",
    "\n",
    "        true_labels  = np.append(true_labels,target.detach().cpu().numpy())\n",
    "        target_score = np.append(target_score,output.detach().cpu().numpy())\n",
    "        prob_score   = np.append(prob_score,torch.sigmoid(output).detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            #1.\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            #2.\n",
    "            print('Train set:  batch loss: {:.4f}, Accuracy: {:.0f}% '.format(\n",
    "                loss.item() ,accuracy))\n",
    "            \n",
    "    train_auroc = roc_auc_score(true_labels, prob_score)\n",
    "    Train_AUROC.append(train_auroc)\n",
    "    \n",
    "    \"\"\"label and target score save\"\"\"\n",
    "    np.save(train_prob_auroc_save_path +'/true_labels.npy',true_labels)\n",
    "    np.save(train_prob_auroc_save_path +'/target_score.npy',target_score)\n",
    "    np.save(train_prob_auroc_save_path +'/target_prob.npy',prob_score)\n",
    "\n",
    "    \n",
    "    \"\"\"Validation\"\"\"\n",
    "    \n",
    "    valid_prob_auroc_save_path = folder_path2 + '/epoch = ' + str(epoch) + '/validation'\n",
    "\n",
    "    try:\n",
    "        if not(os.path.isdir(valid_prob_auroc_save_path)):\n",
    "            os.makedirs(os.path.join(valid_prob_auroc_save_path))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total = len(validation_loader.dataset)\n",
    "    \n",
    "    true_labels  = np.array([]) # ideal label\n",
    "    target_score = np.array([]) # ouput score\n",
    "    prob_score   = np.array([]) # ouput prob\n",
    "    \n",
    "    pred_labels   = np.array([]) # model prediction\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data,features, target) in enumerate(validation_loader):\n",
    "            data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "            features = features.to(device, dtype=torch.float)\n",
    "            \n",
    "            output = model(data,features)\n",
    "\n",
    "            \"\"\"pred(BCE loss)\"\"\"\n",
    "            pred = torch.round(torch.sigmoid(output))\n",
    "            \n",
    "            \"\"\"loss\"\"\"\n",
    "            loss = criterion(output.view_as(target), target)\n",
    "            valid_loss += loss.item()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            \"\"\"auroc inputs\"\"\"\n",
    "            true_labels  = np.append(true_labels,np.array(target.cpu()))\n",
    "            target_score = np.append(target_score,np.array(output.cpu()))\n",
    "            prob_score   = np.append(prob_score,np.array(torch.sigmoid(output).cpu()))\n",
    "            \n",
    "            pred_labels   = np.append(pred_labels,np.array(torch.round(torch.sigmoid(output)).cpu()))\n",
    "            \n",
    "            \n",
    "        \n",
    "        valid_auroc = roc_auc_score(true_labels, prob_score)\n",
    "        Validation_AUROC.append(valid_auroc)\n",
    "        \n",
    "        \"\"\"valid auroc figure save\"\"\"\n",
    "        auc_save_path = valid_prob_auroc_save_path +'/ROC Curve.png'\n",
    "\n",
    "        FPR, TPR, thresholds = roc_curve(true_labels, prob_score)\n",
    "\n",
    "        \"\"\"label and target score save\"\"\"\n",
    "        np.save(valid_prob_auroc_save_path +'/true_labels.npy',true_labels)\n",
    "        np.save(valid_prob_auroc_save_path +'/target_score.npy',target_score)\n",
    "        np.save(valid_prob_auroc_save_path +'/target_prob.npy',prob_score)\n",
    "        \n",
    "        \"\"\"calculate sen & spe\"\"\"\n",
    "        _, _, _, _, sen,spe,_,_ = model_performance(true_labels,pred_labels)\n",
    "        Validation_Sen.append(sen)\n",
    "        Validation_Spe.append(spe)\n",
    "                                      \n",
    "        \n",
    "\n",
    "    \"\"\"Loss and ACC \"\"\"\n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss /= len(validation_loader)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "    \n",
    "    Train_ACC.append(sum(Train_baths_ACC)/len(Train_baths_ACC))\n",
    "    valid_accuracy = 100. * correct / total\n",
    "    Validation_ACC.append(valid_accuracy)\n",
    "    \n",
    "    print('------------------------------------------')\n",
    "    print('Valid set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        valid_loss, correct, total, valid_accuracy))\n",
    "    print('Valid set: AUROC: {:.4f}'.format(valid_auroc))\n",
    "    print('Valid set: Sensitivity: {:.4f}'.format(sen))\n",
    "    print('Valid set: Specificity: {:.4f}'.format(spe))\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "    \n",
    "    \"\"\"Save best model\"\"\"\n",
    "    \n",
    "    if valid_auroc > best_auroc:\n",
    "        torch.save(model, best_model_save_path)\n",
    "        print(\"save model\")\n",
    "        print('-------------------------------------------')\n",
    "        best_acc = valid_accuracy\n",
    "        best_epoch = epoch\n",
    "        best_auroc = valid_auroc\n",
    "        #best_sen = sen\n",
    "        train_acc_cul = sum(Train_baths_ACC)/len(Train_baths_ACC)#best model save시 현재 epoch의 train acc save.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b0be7",
   "metadata": {},
   "source": [
    "# Model save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = folder_path +'/'+ 'experiment '+ str(experiment_num)\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a65002",
   "metadata": {},
   "source": [
    "# Figure and Save Path init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_path = result_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d231fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_save_path = fig_save_path + str(experiment_num) +'/Loss.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(avg_train_losses)+1),avg_train_losses, label='Training Loss')\n",
    "plt.plot(range(1,len(avg_valid_losses)+1),avg_valid_losses, label='Validation Loss')\n",
    "\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlim(0, len(avg_train_losses)+1) \n",
    "plt.ylim(0, 2) \n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(loss_save_path, dpi = 200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf26b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_save_path = fig_save_path + str(experiment_num) +'/Acc.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot (range(1,len(Train_ACC)+1),Train_ACC, label='Train ACC' )\n",
    "plt.plot (range(1,len(Validation_ACC)+1),Validation_ACC, label='Validation ACC')\n",
    "\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('acc')\n",
    "\n",
    "plt.xlim(0, len(Train_ACC)+1)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'lower right', fancybox = False, edgecolor = 'k', framealpha = 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(acc_save_path, dpi = 200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_save_path = fig_save_path + str(experiment_num) +'/Acc and AUROC.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot (range(1,len(Train_ACC)+1),np.array(Train_ACC)/100, label='Train ACC',alpha = 0.2 )\n",
    "plt.plot (range(1,len(Validation_ACC)+1),np.array(Validation_ACC)/100, label='Validation ACC',alpha = 0.2)\n",
    "plt.plot (range(1,len(Train_AUROC)+1),np.array(Train_AUROC), label='Train AUROC')\n",
    "plt.plot (range(1,len(Validation_AUROC)+1),np.array(Validation_AUROC), label='Validation AUROC')\n",
    "\n",
    "plt.vlines(best_epoch,0.1,1.0,'r','--')\n",
    "plt.text(best_epoch, 0.1,' best model',fontsize = 15)\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('acc and auroc')\n",
    "\n",
    "plt.xlim(0, len(Train_ACC)+1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'lower right', fancybox = False, edgecolor = 'k', framealpha = 1.0,fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(acc_save_path, dpi = 200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_spe_save_path = fig_save_path + str(experiment_num) +'/Validatin Sen and Spe.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(Validation_Sen)+1),np.array(Validation_Sen)*0.01, color='blue', label='Validation Sensitivity')\n",
    "plt.plot(range(1,len(Validation_Spe)+1),np.array(Validation_Spe)*0.01, color='green', label='Validation Specificity')\n",
    "plt.plot (range(1,len(Train_AUROC)+1),np.array(Train_AUROC), label='Train AUROC' ,alpha = 0.3)\n",
    "plt.plot (range(1,len(Validation_AUROC)+1),np.array(Validation_AUROC), label='Validation AUROC',alpha = 0.3)\n",
    "\n",
    "plt.vlines(best_epoch,0.1,1.0,'r','--')\n",
    "plt.text(best_epoch, 0.1,' best model',fontsize = 15)\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('metrics')\n",
    "\n",
    "plt.xlim(0, len(Validation_Sen)+1) \n",
    "plt.ylim(0, 1) \n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'lower right', fancybox = False, edgecolor = 'k', framealpha = 1.0,fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(sen_spe_save_path, dpi = 200) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc389a6",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca06a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['loss'] = 'BCE'\n",
    "\n",
    "Result['epochs'] = epochs\n",
    "Result['learning rate'] = lr\n",
    "Result['batch size'] = batch_size\n",
    "Result['test batch size'] = test_batch_size\n",
    "\n",
    "Result['best_epoch'] = best_epoch\n",
    "Result['train_acc_at_last_epoch'] = Train_ACC[-1]\n",
    "Result['train_acc_at_best_epoch'] = train_acc_cul\n",
    "\n",
    "Result['validation_acc_at_last_epoch'] = Validation_ACC[-1]\n",
    "Result['validation_acc_at_best_epoch'] = best_acc\n",
    "Result['validation_auroc_at_best_epoch'] = best_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8043a",
   "metadata": {},
   "source": [
    "# Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "experiment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(best_model_save_path)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b917a",
   "metadata": {},
   "source": [
    "# Test without Youden index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff5a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_labels  = np.array([]) \n",
    "target_score = np.array([]) \n",
    "prob_score   = np.array([]) # ouput prob\n",
    "pred_labels  = np.array([]) \n",
    "\n",
    "\"\"\"test\"\"\"\n",
    "model.eval()\n",
    "    \n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data,features, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        features = features.to(device, dtype=torch.float)\n",
    "        \n",
    "        \"\"\"pred(BCE loss)\"\"\"\n",
    "        pred = torch.round(torch.sigmoid(output))\n",
    "        \n",
    "        \n",
    "        \"\"\"loss\"\"\"\n",
    "        loss = criterion(output.view_as(target), target)\n",
    "        test_loss += loss.item()\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "        true_labels = np.append(true_labels,np.array(target.cpu())) \n",
    "        target_score = np.append(target_score,np.array(output.cpu()))\n",
    "        prob_score   = np.append(prob_score,np.array(torch.sigmoid(output).cpu()))\n",
    "        pred_labels = np.append(pred_labels,np.array(pred.cpu())) \n",
    "        \n",
    "        print('test: [{}/{}] '.format(batch_idx,len(test_loader)-1))\n",
    "        \n",
    "        \n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100. * correct / total\n",
    "\n",
    "print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    test_loss, correct, total, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['test_acc'] = test_accuracy\n",
    "Result['test_auroc'] = roc_auc_score(true_labels, prob_score)\n",
    "\n",
    "\n",
    "test_path = folder_path +'/test'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(test_path)):\n",
    "        os.makedirs(os.path.join(test_path))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise\n",
    "\n",
    "\n",
    "performance = [roc_curve(true_labels, target_score)]\n",
    "np.save(test_path +'/test performance.npy',performance)\n",
    "\n",
    "np.save(test_path +'/true_labels.npy',true_labels)\n",
    "np.save(test_path +'/target_score.npy',target_score)\n",
    "np.save(test_path +'/target_prob.npy',prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_save_path = fig_save_path + str(experiment_num) +'/Testset ROC Curve.png'\n",
    "\n",
    "FPR, TPR, thresholds = roc_curve(true_labels, prob_score)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(FPR, TPR, label=r'model performance (AUROC %0.4f)' % (roc_auc_score(true_labels, prob_score)),lw=2, alpha=.8)\n",
    "plt.plot([0,1],[0,1],'--', color='red') # 대각선\n",
    "plt.title('ROC Curve', fontsize=18)\n",
    "plt.xlabel('1-specificity', fontsize=18)\n",
    "plt.ylabel('sensitivity', fontsize=18)\n",
    "\n",
    "plt.legend(loc = 'lower right', fontsize=18)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.savefig(auc_save_path, dpi = 200)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d67fa3",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6774138",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp, sen,spe,ppv,npv = model_performance(true_labels,pred_labels)\n",
    "\n",
    "print(\"모델의 Sensitivity:\",sen)\n",
    "print(\"모델의 Specificity:\",spe)\n",
    "print(\"모델의 PPV:\",ppv)\n",
    "print(\"모델의 NPV:\",npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['TN'] = tn\n",
    "Result['FP'] = fp\n",
    "Result['FN'] = fn\n",
    "Result['TP'] = tp\n",
    "\n",
    "Result['Sensitivity'] = sen\n",
    "Result['Specificity'] = spe\n",
    "Result['PPV'] = ppv\n",
    "Result['NPV'] = npv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017e248",
   "metadata": {},
   "source": [
    "# Test with Youden index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b216a0",
   "metadata": {},
   "source": [
    "## calculate youden index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cef799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_labels  = np.array([]) \n",
    "target_score = np.array([]) \n",
    "prob_score   = np.array([]) \n",
    "pred_labels  = np.array([]) \n",
    "\n",
    "\"\"\"Validation\"\"\"\n",
    "model.eval()\n",
    "    \n",
    "valid_loss = 0\n",
    "correct = 0\n",
    "total = len(validation_loader.dataset)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for batch_idx, (data,features, target) in enumerate(validation_loader):\n",
    "            data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "            features = features.to(device, dtype=torch.float)\n",
    "            \n",
    "            output = model(data,features)\n",
    "            \n",
    "            \"\"\"pred(BCE loss)\"\"\"\n",
    "            pred = torch.round(torch.sigmoid(output))\n",
    "            \n",
    "            \"\"\"결과값 누적.\"\"\"\n",
    "            true_labels = np.append(true_labels,np.array(target.cpu())) \n",
    "            target_score = np.append(target_score,np.array(output.cpu()))\n",
    "            prob_score   = np.append(prob_score,np.array(torch.sigmoid(output).cpu()))\n",
    "            pred_labels = np.append(pred_labels,np.array(pred.cpu()))  \n",
    "    \n",
    "            print('validation: [{}/{}] '.format(batch_idx,len(validation_loader)-1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ad2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Youden’s J statistic. / J = Sensitivity + Specificity – 1\"\"\"\n",
    "\n",
    "# calculate roc curves\n",
    "#FPR, TPR, thresholds = roc_curve(true_labels, target_score)\n",
    "FPR, TPR, thresholds = roc_curve(true_labels, prob_score)\n",
    "\n",
    "# get the best threshold\n",
    "J = TPR - FPR\n",
    "idx = argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "\n",
    "print('Best Threshold=%f, sensitivity = %.3f, specificity = %.3f, J=%.3f' % (best_thresh, TPR[idx], 1-FPR[idx], J[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_save_path = fig_save_path + str(experiment_num) +'/Validset ROC Curve.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(FPR, TPR, label=r'model performance (AUROC %0.4f)' % (roc_auc_score(true_labels, prob_score)),lw=2, alpha=.8)\n",
    "plt.scatter(FPR[idx], TPR[idx], marker='+', s=100, color='r', \n",
    "            label='Best threshold = %.3f, \\nSensitivity = %.3f, \\nSpecificity = %.3f' % (best_thresh, TPR[idx], 1-FPR[idx]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'--', color='red') \n",
    "plt.title('ROC Curve', fontsize=18)\n",
    "plt.xlabel('1-specificity', fontsize=18)\n",
    "plt.ylabel('sensitivity', fontsize=18)\n",
    "\n",
    "plt.legend(loc = 'lower right', fontsize=18)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.savefig(auc_save_path, dpi = 200) \n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265749ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['best threshold'] = best_thresh\n",
    "Result['sensitivity_in_best threshold'] =  TPR[idx]\n",
    "Result['specificity_in_best threshold'] =  1-FPR[idx]\n",
    "Result['J_best threshold'] =  J[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41d7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_labels  = np.array([]) \n",
    "target_score = np.array([]) \n",
    "prob_score   = np.array([]) \n",
    "pred_labels  = np.array([]) \n",
    "\n",
    "\"\"\"test\"\"\"\n",
    "model.eval()\n",
    "    \n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data,features, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        features = features.to(device, dtype=torch.float)\n",
    "\n",
    "        \n",
    "        \"\"\"pred(BCE loss)\"\"\"\n",
    "        #pred = torch.round(torch.sigmoid(output))\n",
    "        pred = (torch.sigmoid(output) > best_thresh).int() \n",
    "        \n",
    "        \n",
    "        \"\"\"loss\"\"\"\n",
    "        loss = criterion(output.view_as(target), target)\n",
    "        test_loss += loss.item()\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        \n",
    "        true_labels = np.append(true_labels,np.array(target.cpu())) # 실제 라벨\n",
    "        target_score = np.append(target_score,np.array(output.cpu()))\n",
    "        prob_score   = np.append(prob_score,np.array(torch.sigmoid(output).cpu()))\n",
    "        pred_labels = np.append(pred_labels,np.array(pred.cpu()))  # 예측 결과\n",
    "        \n",
    "        print('test: [{}/{}] '.format(batch_idx,len(test_loader)-1))\n",
    "        \n",
    "        \n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100. * correct / total\n",
    "\n",
    "print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "    test_loss, correct, total, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['test_acc_youden_index'] = test_accuracy\n",
    "Result['test_auroc_youden_index'] = roc_auc_score(true_labels, prob_score)\n",
    "\n",
    "\n",
    "test_path = folder_path +'/test_youden_index'\n",
    "\n",
    "try:\n",
    "    if not(os.path.isdir(test_path)):\n",
    "        os.makedirs(os.path.join(test_path))\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Failed to create directory!!!!!\")\n",
    "        raise\n",
    "\n",
    "\n",
    "performance = [roc_curve(true_labels, prob_score)]\n",
    "np.save(test_path +'/test performance_youden_index.npy',performance)\n",
    "\n",
    "np.save(test_path +'/true_labels.npy',true_labels)\n",
    "np.save(test_path +'/target_score.npy',target_score)\n",
    "np.save(test_path +'/target_prob.npy',prob_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ea37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_save_path = fig_save_path + str(experiment_num) +'/Testset ROC Curve with Youden index.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(FPR, TPR, label=r'model performance (AUROC %0.4f)' % (roc_auc_score(true_labels, prob_score)),lw=2, alpha=.8)\n",
    "plt.plot([0,1],[0,1],'--', color='red') \n",
    "plt.title('ROC Curve', fontsize=18)\n",
    "plt.xlabel('1-specificity', fontsize=18)\n",
    "plt.ylabel('sensitivity', fontsize=18)\n",
    "\n",
    "plt.legend(loc = 'lower right', fontsize=18)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.savefig(auc_save_path, dpi = 200) \n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp, sen,spe,ppv,npv = model_performance(true_labels,pred_labels)\n",
    "\n",
    "print(\"Sensitivity:\",sen)\n",
    "print(\"Specificity:\",spe)\n",
    "print(\"PPV:\",ppv)\n",
    "print(\"NPV:\",npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26644643",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result['TN_youden_index'] = tn\n",
    "Result['FP_youden_index'] = fp\n",
    "Result['FN_youden_index'] = fn\n",
    "Result['TP_youden_index'] = tp\n",
    "\n",
    "Result['Sensitivity_youden_index'] = sen\n",
    "Result['Specificity_youden_index'] = spe\n",
    "Result['PPV_youden_index'] = ppv\n",
    "Result['NPV_youden_index'] = npv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46703aad",
   "metadata": {},
   "source": [
    "# Result save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Result,index = [0])\n",
    "df.to_excel(folder_path +'/Result.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
